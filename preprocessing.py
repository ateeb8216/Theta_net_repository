# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H5UQ--MvACc2umL7amm02W-ZrmnLL0tk
"""

preprocessing.py
----------------
This module handles text preprocessing, tokenization, lemmatization, padding,
and label encoding for the Hierarchical LSTM-CNN News Classification Model (HLNN).
It also includes placeholders for hybrid semantic augmentation for the BBC dataset.

Author: abdullah
Python Version: 3.11
"""

import pandas as pd
import numpy as np
import spacy
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load spaCy English model
nlp = spacy.load("en_core_web_sm")

MAX_SEQUENCE_LENGTH = 300  # Consistent input length
EMBEDDING_DIM = 50

def clean_text(text):
    """Performs lowercasing, punctuation removal, stopword removal, and lemmatization."""
    doc = nlp(text.lower())
    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]
    return " ".join(tokens)

def load_dataset(path):
    """
    Loads a dataset CSV file and cleans text.
    Expects columns: 'text' and 'label'.
    """
    df = pd.read_csv(path)
    df.drop_duplicates(inplace=True)
    df['text'] = df['text'].apply(clean_text)
    return df

def encode_labels(labels):
    """Encodes string labels into integers and returns one-hot encoding."""
    le = LabelEncoder()
    y = le.fit_transform(labels)
    return y, le

def tokenize_texts(texts):
    """Tokenizes and pads sequences to MAX_SEQUENCE_LENGTH."""
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(texts)
    sequences = tokenizer.texts_to_sequences(texts)
    padded = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')
    return padded, tokenizer

# Placeholder for hybrid semantic augmentation
def hybrid_semantic_augmentation(df):
    """
    Expands underrepresented datasets (like BBC News) using back-translation
    and transformer-based paraphrasing.
    Currently a placeholder function.
    """
    # Implement back-translation or transformer paraphrasing here
    return df
# -*- coding: utf-8 -*-
"""evaluate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H5UQ--MvACc2umL7amm02W-ZrmnLL0tk
"""

evaluate.py
-----------
Evaluation of HLNN on validation/test sets.
Computes Accuracy, Precision, Recall, F1-Score, and provides attention-based visualizations.

Author: abdullah
Python Version: 3.11
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from preprocessing import load_dataset, encode_labels, tokenize_texts
from model_hlnn import build_hlnn

# Load evaluation dataset
EVAL_PATH = "data/hybrid_dataset.csv"
eval_df = load_dataset(EVAL_PATH)
y_eval, label_encoder = encode_labels(eval_df['label'])
y_eval_cat = np.eye(9)[y_eval]
X_eval, tokenizer = tokenize_texts(eval_df['text'])
vocab_size = len(tokenizer.word_index)

# Load model
model, attention_weights = build_hlnn(vocab_size)
model.load_weights("HLNN_best_model.h5")

# Predict
y_pred_probs = model.predict(X_eval)
y_pred = np.argmax(y_pred_probs, axis=1)

# Metrics
print(classification_report(y_eval, y_pred, target_names=label_encoder.classes_))

# Confusion matrix
cm = confusion_matrix(y_eval, y_pred)
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt="d", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("HLNN Confusion Matrix")
plt.show()

# Attention visualization placeholder
def plot_attention(tokenizer, text, attention_weights):
    tokens = text.split()[:300]
    weights = attention_weights[0][:len(tokens)]
    plt.figure(figsize=(12,4))
    plt.bar(tokens, weights)
    plt.xticks(rotation=90)
    plt.title("Token Attention Weights")
    plt.show()

# Example: visualize attention for first sample
plot_attention(tokenizer, eval_df['text'].iloc[0], np.random.rand(1, 300))  # Replace with actual attention extraction